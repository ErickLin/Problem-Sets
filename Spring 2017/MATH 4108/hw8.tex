\documentclass[12pt]{article}

%Packages Used%
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{latexsym}
\usepackage{amsfonts,setspace}
\usepackage{fullpage}
%\usepackage[pdftex,pagebackref,hypertexnames=false, colorlinks, citecolor=black, linkcolor=blue, urlcolor=red]{hyperref}
\usepackage{comment}
\usepackage{enumitem}
\usepackage[margin=1in]{geometry}


\setlength{\abovedisplayskip}{3mm}
\setlength{\belowdisplayskip}{3mm}
\setlength{\abovedisplayshortskip}{0mm}
\setlength{\belowdisplayshortskip}{2mm}
\setlength{\baselineskip}{12pt}
\setlength{\normalbaselineskip}{12pt}

\setlength\parindent{0pt} % paragraph indentation

\newcommand{\blank}{\underline{~~~~~~~~~}}
\newcommand{\RR}{\mathbb{R}}
\newcommand{\QQ}{\mathbb{Q}}
\newcommand{\CC}{\mathbb{C}}
\newcommand{\ZZ}{\mathbb{Z}}
\newcommand{\PP}{\mathbb{P}}
\newcommand{\FF}{\mathbb{F}}
\newcommand{\kk}{\mathbf{k}}
\newcommand{\cP}{\mathcal{P}}

\newcommand{\bu}{\mathbf{u}}
\newcommand{\bv}{\mathbf{v}}
\newcommand{\bx}{\mathbf{x}}
\newcommand{\by}{\mathbf{y}}
\newcommand{\bb}{\mathbf{b}}
\newcommand{\bc}{\mathbf{c}}
\newcommand{\bp}{\mathbf{p}}
\newcommand{\bq}{\mathbf{q}}
\newcommand{\be}{\mathbf{e}}
\newcommand{\bzero}{\mathbf{0}}
\DeclareMathOperator{\Nul}{Nul}
\DeclareMathOperator{\Mod}{mod}
\DeclareMathOperator{\ord}{ord}
\DeclareMathOperator{\GL}{GL}
\DeclareMathOperator{\SL}{SL}
\DeclareMathOperator{\Hom}{Hom}
\DeclareMathOperator{\End}{End}
\DeclareMathOperator{\Ind}{Ind}
\DeclareMathOperator{\Gal}{Gal}
\DeclareMathOperator{\im}{im}
\DeclareMathOperator{\tr}{tr}

\renewcommand{\And}{\wedge}
\newcommand{\Or}{\vee}
\newcommand{\Implies}{\Rightarrow}
\newcommand{\Not}{\sim}



\normalbaselines
\pagestyle{empty}
\raggedbottom
\begin{document}

\noindent
\textbf{Name: Erick Lin} \smallskip  \\
\textbf{Collaborators:} \smallskip \\ %%% List anyone with whom you discussed the problems
\textbf{Outside resources:} \smallskip \\ %%% List all resources used OTHER than the textbook, lecture notes, quizzes, worksheets, and previous homework assignments.

\begin{center}
{
Math 4108, Algebra II \\
HW 8 --- Due April 21, 2017 (Friday)
}
\end{center}

\iffalse
Do the following problems from Lang:\\
V\S6, 1, 2.\\
V\S7, 2, 3, 4.\\
V\S8, 1, 6, 7.\\
V\S9, 1, 4, 6, 8, 9, 25.
\fi
\subsection*{V,\S6.}
\begin{enumerate}
    \item[1.]
        \boldmath\textbf{Let $A$ be an abelian group with a finite number of generators, and assume that $A$ does not contain any element of finite period except the unit element. We write $A$ additively. Let $d$ be a positive integer. Show that the map $x \mapsto dx$ is an injective homomorphism of $A$ into itself, whose image is isomorphic to $A$.
        }\unboldmath \par
        $da \in A$ for any $a$ by closure, and for any element that can be written as $da$ for some $a$, $a$ must be unique because no element has finite period except for 0. Let $\{ a_1, \cdots, a_m \}$ be generators of $A$. %Then any $a, a' \in A$ can be written as $a = c_1 a_1 + \cdots + c_m a_m, a' = c_1' a_1 + \cdots + c_m' a_m$ with $c_i, c_i' \in \mathbb{Z}$, and
        We also have that
        \begin{align*}
            da + da' = d(a + a').
        \end{align*}
        Any injective morphism of objects, including $x \mapsto dx : A \to A$, is by definition an embedding.

    \item[2.]
        \boldmath\textbf{Given notation as in Exercise 1, let $\{ a_1, \cdots, a_m \}$ be a set of generators of $A$, $\{ a_1, \cdots, a_r \}$ a maximal subset linearly independent over $\mathbb{Z}$, and $B$ the subgroup generated by $a_1, \cdots, a_r$. Show that there exists a positive integer $d$ such that $dx$ lies in $B$ for all $x$ in $A$. Using Theorem 6.3 and Exercise 1, conclude that $A$ has a basis.
        }\unboldmath \par
        For all $r + 1 \leq k \leq m$, there exist $c_1, \cdots, c_r, c_k \in \mathbb{Z}$ such that
        \begin{align*}
            c_1 a_1 + \cdots + c_r a_r + c_k a_k = 0
        \end{align*}
        by linear dependence. We can also see by subtracting from both sides that $-c_k a_k$ is contained in the subgroup generated by $a_1, \cdots, a_r$, and this is also true for any multiple of $-c_k a_k$. Now let $d = -\text{lcm}\{ c_{r + 1}, \cdots, c_m \}$. Any $x \in A$ can be written as a linear combination of the generators with coefficients in $\mathbb{Z}$, and sending $x \mapsto dx$ sends all the terms that are multiples of $a_{r + 1}, \cdots, a_m$ to zero. \par
        Since $\{ a_1, \cdots, a_r \}$ forms a basis of $B$, and the image of $x \mapsto dx : A \to B$ is isomorphic to $A$ by Exercise 1 and hence a subgroup of $B$, Theorem 6.3 states that $A$ has a basis with $\leq r$ elements.
\end{enumerate}
\subsection*{V,\S7.}
\begin{enumerate}
    \item[2.]
        \boldmath\textbf{Let $M$ be a finitely generated torsion module over $R$, and denote by $a_M : M\to M$ multiplication by $a$. Prove that there exists $a \in R, a \neq 0$ such that $a_M = 0$.
        }\unboldmath \par
        Let $\{ v_1, \cdots, v_m \}$ be the generators of $M$. Then for all $v_i$, there exists $a_i \in R$ such that $a_i v_i = 0$. Now let $a = \text{lcm}\{ a_1, \cdots, a_m \} \in R$. Any $v \in M$ can be written as a linear combination of the generators, so $av = 0$.

    \item[3.]
        \boldmath\textbf{Let $p$ be a prime of $R$. Prove that $R/pR$ is a simple $R$-module.
        }\unboldmath \par
        $R/pR$ is an $R$-module because the product of any element of $R$ with any element of $R/pR$ is in $R/pR$. $R/pR$ is simple because for any $q \in R$ such that $q \notin \langle p \rangle$, there exists $s, t \in R$ such that $ps + qt = 1$, so $qt = 1 + \langle p \rangle$ and thus $q$ generates $R/pR$.

    \item[4.]
        \boldmath\textbf{Let $a \in R, a \neq 0$. If $a$ is not prime, prove that $R/aR$ is not a simple $R$-module.
        }\unboldmath \par
        Since $a$ is not prime, it has a proper divisor $p$. Then $R/pR$ is a proper submodule of $R/aR$.
\end{enumerate}
\subsection*{V,\S8.}
\begin{enumerate}
    \item[1.]
        \boldmath\textbf{Let $V$ be an $n$-dimensional vector space and assume that the characteristic polynomial of a linear map $A : V \to V$ has $n$ distinct roots. Show that $V$ has a basis consisting of the eigenvectors of $A$.
        }\unboldmath \par
        The eigenvalues are the roots of the characteristic polynomial, so $A$ has $n$ distinct eigenvalues. Then by Theorem 8.2, the $n$ corresponding eigenvectors are linearly independent, and hence they form a basis because $V$ is $n$-dimensional.

    \item[6.]
        \boldmath\textbf{Let $A$, $B$ be square matrices of the same size. Show that the eigenvalues of $AB$ are the same as the eigenvalues of $BA$.
        }\unboldmath \par
        Let $\lambda$ be an eigenvalue of $AB$ and $v$ its corresponding eigenvector, so that $ABv = \lambda v$. Multiplying both sides on the left by $B$ gives $BABv = \lambda Bv$, yielding that $\lambda$ is also an eigenvalue of $BA$ with $Bv \neq 0$ (since otherwise $ABv = 0$, contradicting $ABv = \lambda v$) its corresponding eigenvector.

    \item[7.]
        \boldmath\textbf{\emph{(Artin's theorem.)} Let $G$ be a group, and let $f_1, \cdots, f_n : G \to K^*$ be distinct homomorphisms of $G$ into the multiplicative group of a field. In particular, $f_1, \cdots, f_n$ are functions of $G$ into $K$. Prove that these functions are linearly independent over $K$.
        }\unboldmath \par
        We prove this by induction on $n$, in a similar spirit as in Theorem 8.2, First, $f_1$ is linearly independent, so assume $n > 1$ and the statement holds for $n - 1$. Suppose we have a relation
        \begin{align*}
            c_1 f_1 + \cdots + c_n f_n = 0
        \end{align*}
        for scalars $c_i \in K$, which means that for all $x, y \in G$,
        \begin{gather} \label{eq:indep}
            \begin{split}
                c_1 f_1(x) + \cdots + c_n f_n(x) = 0 \\
                \Rightarrow c_1 f_1(y) f_1(x) + \cdots + c_n f_1(y) f_n(x) = 0
            \end{split}
        \end{gather}
        and since the $f_i$ are homomorphisms,
        \begin{gather} \label{eq:homom}
            \begin{split}
                c_1 f_1(xy) + \cdots + c_n f_n(xy) = 0 \\
                \Rightarrow c_1 f_1(x) f_1(y) + \cdots + c_n f_n(x) f_n(y) = 0.
            \end{split}
        \end{gather}
        Subtracting (\ref{eq:indep}) from (\ref{eq:homom}), we have
        \begin{gather*}
            c_2 (f_2(y) - f_1(y)) f_2(x) + \cdots + c_n (f_n(y) - f_1(y)) f_n(x) = 0 \\
            \Rightarrow c_2 (f_2(y) - f_1(y)) f_2 + \cdots + c_n (f_n(y) - f_1(y)) f_n = 0,
        \end{gather*}
        but by the induction hypothesis $f_2, \cdots, f_n$ are linearly independent, so $c_2(f_2(y) - f_1(y)) = \cdots = c_n(f_n(y) - f_1(y)) = 0$. If there exists $i$ such that $c_i \neq 0$, we must have that $f_i(y) = f_1(y)$. But by the inductive hypothesis, $f_i$ and $f_1$ are linearly independent so $f_i \neq f_1$, and hence there exists $y$ such that $f_i(y) \neq f_1(y)$, a contradiction. In conclusion, $c_1 = \cdots = c_n = 0$, and the $f_1, \cdots, f_n$ are linearly independent.
\end{enumerate}
\subsection*{V,\S9.}
\begin{enumerate}
    \item[1.]
        \boldmath\textbf{Let $M$ be an $n \times n$ diagonal matrix with eigenvalues $\lambda_1, \cdots, \lambda_r$. Suppose that $\lambda_i$ has multiplicity $m_i$. Write down the minimal polynomial of $M$, and also write down its characteristic polynomial.
        }\unboldmath \par
        The minimal polynomial is $(x - \lambda_1)(x - \lambda_2)\cdots(x - \lambda_r)$, because subtracting $\lambda_i$ from $A$ sends all the elements along the diagonal equal to $\lambda_i$ to zero, and the product of diagonal matrices is diagonal, with any zero entries in either one remaining zero in the product. The characteristic polynomial is $(x - \lambda_1)^{m_1} (x - \lambda_2)^{m_2} \cdots (x - \lambda_r)^{m_r}$.

    \item[4.]
        \boldmath\textbf{Let $A : V \to V$ be an endomorphism, and $V$ finite-dimensional. Suppose that $A^3 = A$. Show that $V$ is the direct sum
            \begin{align*}
                V = V_0 \oplus V_1 \oplus V_{-1},
            \end{align*}
            where $V_0 = \ker A$, $V_1$ is the $(+1)$-eigenspace of $A$, and $V_{-1}$ is the $(-1)$-eigenspace of $A$.
        }\unboldmath \par
        $f(t) = t^{r_0} (t - 1)^{r_1} (t + 1)^{r_{-1}}$ is the characteristic polynomial of $A$, and $f(A) = O$ by the Cayley-Hamilton theorem. By Theorem 9.2, $V$ is the direct sum of $\ker(A - 0I)^{r_0} = \ker A$, $\ker(A - I)^{r_1} = \ker(A - I)$, and $\ker(A + I)^{r_{-1}} = \ker(A + I)$.

    \item[6.]
        \boldmath\textbf{Prove that $A$ is diagonalizable if and only if the minimal polynomial of $A$ has all roots of multiplicity 1.
        }\unboldmath \par
        %We know that $A$ is diagonalizable if and only if it has $\dim A$ distinct eigenvalues, meaning that the characteristic polynomial has no repeated roots, which implies that the minimal polynomial also has no repeated roots since the minimal polynomial divides the characteristic polynomial. Conversely, if the minimal polynomial has repeated roots, then so does the characteristic polynomial.
        The minimal polynomial of an $r \times r$ matrix of the form
        \begin{align*}
            \left[ \begin{array}{ccccc}
                \alpha & 1 & 0 & \cdots & 0 \\
                0 & \alpha & 1 & \ddots & 0 \\
                \vdots & \ddots & \ddots & \ddots & 0 \\
                \vdots & \ddots & \ddots & \ddots & 1 \\
                0 & 0 & 0 & 0 & \alpha
            \end{array} \right]
        \end{align*}
        is $(x - \alpha)^r$. For a diagonalizable matrix, the blocks of the Jordan normal form are each of size $1 \times 1$.

    \item[8.]
        \boldmath\textbf{Let $B$ be an endomorphism of $V$ such that $BA = AB$. Prove that $A, B$ have a common nonzero eigenvector.
        }\unboldmath \par
        Suppose $\lambda$ is an eigenvalue of $B$, with corresponding eigenvector $v$. Then $BAv = ABv = A(\lambda v) = \lambda Av$, so $Av$ is also an eigenvector of $B$ if $Av \neq 0$. In other words, if $\Lambda$ is the eigenspace of $B$ corresponding to $\lambda$, then $A|_{\Lambda}$ maps $\Lambda$ to $\Lambda$, so at least one eigenvector $w$ of $A$ is contained in $\Lambda$. Then $w$ is, by the definition of $\Lambda$, also an eigenvector of $B$.

    \item[9.]
        \boldmath\textbf{Let $B$ be an endomorphism of $V$. Assume that $AB = BA$ and both $A, B$ are diagonalizable. Prove that $A$ and $B$ are simultaneously diagonalizable, that is, $V$ has a basis consisting of elements which are eigenvectors for both $A$ and $B$.
        }\unboldmath \par
        %Because $A$ and $B$ are both diagonalizable, they each have a set of $n$ distinct eigenvectors which forms a basis of $V$. By the proof of Exercise 8, $A$ has an eigenvector in each of the $n$ eigenspaces of $B$ which is by definition an eigenvector of $B$; thus, $A$ and $B$ share all $n$ of their eigenvectors.
        This will be shown by induction. By Exercise 8, $A$ and $B$ have a common eigenvector $v_1$. Assuming that $A$ and $B$ have $k < n$ common eigenvectors $v_1, \cdots, v_k$ let $W$ be the set of vectors perpendicular to $v_1, \cdots, v_k$. Because $A$ and $B$ are diagonalizable, they each have $n - k$ more eigenvectors which span $W$ and, together with $v_1, \cdots, v_k$, form a basis of $V$. Thus, $A|_W$ and $B|_W$ both map $W$ to itself. Then again by Exercise 8, $A|_W$ and $B|_W$ share an eigenvector $v_{k + 1}$. Take $k + 1 = n$.

    \item[25.]
        \boldmath\textbf{Let $F$ be a field and $\text{Mat}_n(F) = M_n(F)$ the ring of $n \times n$ matrices over $F$. For two matrices $X, Y \in M_n(F)$ define $[X, Y] = XY - YX$. Let $L_X : M_n \to M_n$ denote the map such that $L_X(Y) = [X, Y]$.
        }\unboldmath
        \begin{enumerate}
            \item
                \boldmath\textbf{Show that for each $X$, the map $L_X : Y \mapsto [X, Y]$ is a linear map, satisfying
                    \begin{align*}
                        [X, [Y, Z]] = [[X, Y], Z] + [Y, [X, Z]].
                    \end{align*}
                }\unboldmath \par
                Given $Y, Z \in M_n(F)$ and $c \in F$, $L_X(Y + Z) = [X, Y + Z] = X(Y + Z) - (Y + Z)X = (XY - YX) + (XZ - ZX) = L_X(Y) + L_X(Z)$ and $L_X(cY) = [X, cY] = X(cY) - cYX = c(XY - YX) = cL_X(Y)$. \par
                Lastly, $[X, [Y, Z]] = [X, YZ - ZY] = X(YZ - ZY) - (YZ - ZY)X = (XY - YX)Z - Z(XY - YX) + Y(XZ - ZX) - (XZ - ZX)Y = [XY - YX, Z] + [Y, XZ - ZX] = [[X, Y], Z] + [Y, [X, Z]]$.
            \item
                \boldmath\textbf{Let $E_{ij}$ for $i, j = 1, \cdots, n$ be the matrix with $(ij)$-component $1$, and all other components $0$. Then the set of elements $E_{ij}$ is a basis for $M_n$. Let $D_n$ be the vector space of diagonal matrices. For each $H \in D_n$, show that $E_{ij}$ is an eigenvector of $L_H$, with eigenvalue $\alpha_{ij}(H) = h_i - h_j$ (where $h_1, \cdots, h_n$ are the diagonal components of $H$). Show that $\alpha_{ij} : D_n \to F$ is linear.
                }\unboldmath \par
                Given $X \in M_n(F)$, $E_{ij} L_H(X) = E_{ij} (HX - XH) = (h_i - h_j) (HX - XH) = \alpha_{ij} L_H(X)$. \par
                Also, given $H, K \in D_n(F)$ and $c \in F$, $\alpha_{ij}(H + K) = (h_i + k_i) - (h_j + k_j) =  (h_i - h_j) + (k_i - k_j) = \alpha_{ij}(H) + \alpha_{ij}(K)$ and $\alpha_{ij}(cH) = (ch_i - ch_j) = c(h_i - h_j) = c\alpha_{ij}(H)$.
            \item
                \boldmath\textbf{For two linear maps $A, B$ of a vector space, define $[A, B] = AB - BA$. Show that $L_{[X, Y]} = [L_X, L_Y]$.%, so $L$ is also a homomorphism for the Lie product.
                }\unboldmath \par
                Given $Z \in M_n(F)$, $L_{[X, Y]}(Z) = (XY - YX)Z - Z(XY - YX) = (XYZ - ZXY) - (YXZ - ZYX) = [L_X, L_Y](Z)$.
        \end{enumerate}
\end{enumerate}

\end{document}
